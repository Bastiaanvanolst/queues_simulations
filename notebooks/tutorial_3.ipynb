{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3, solutions\n",
    "\n",
    "\n",
    "This solution is a jupyter notebook which allows you to directly interact with\n",
    "the code so that you can see the effect of any changes you may like to make.\n",
    "\n",
    "Author: Nicky van Foreest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klara 18\n",
      "Piet 20\n",
      "Jan 21\n",
      "Cynthia 25\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "from heapq import heappop, heappush\n",
    "from scipy.stats import uniform, expon\n",
    "\n",
    "scipy.random.seed(3)\n",
    "\n",
    "\n",
    "def sort_ages():\n",
    "    stack = []\n",
    "\n",
    "    heappush(stack, (21, \"Jan\"))\n",
    "    heappush(stack, (20, \"Piet\"))\n",
    "    heappush(stack, (18, \"Klara\"))\n",
    "    heappush(stack, (25, \"Cynthia\"))\n",
    "\n",
    "    while stack:\n",
    "        age, name = heappop(stack)\n",
    "        print(name, age)\n",
    "\n",
    "\n",
    "sort_ages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Klara Motorola\n",
      "20 Piet Apple\n",
      "21 Jan Huawei\n",
      "25 Cynthia Nexus\n"
     ]
    }
   ],
   "source": [
    "def sort_ages_with_more_info():\n",
    "    stack = []\n",
    "\n",
    "    heappush(stack, (21, \"Jan\", \"Huawei\"))\n",
    "    heappush(stack, (20, \"Piet\", \"Apple\"))\n",
    "    heappush(stack, (18, \"Klara\", \"Motorola\"))\n",
    "    heappush(stack, (25, \"Cynthia\", \"Nexus\"))\n",
    "\n",
    "    while stack:\n",
    "        age, name, phone = heappop(stack)\n",
    "        print(age, name, phone)\n",
    "\n",
    "\n",
    "sort_ages_with_more_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# void  code for numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARRIVAL = 0\n",
    "DEPARTURE = 1\n",
    "\n",
    "stack = []  # this is the event stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self):\n",
    "        self.arrival_time = 0\n",
    "        self.service_time = 0\n",
    "        self.departure_time = 0\n",
    "        self.queue_length_at_arrival = 0\n",
    "\n",
    "    def sojourn_time(self):\n",
    "        return self.departure_time - self.arrival_time\n",
    "\n",
    "    def waiting_time(self):\n",
    "        return self.sojourn_time() - self.service_time\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.arrival_time}, {self.service_time}, {self.departure_time}\\n\"\n",
    "\n",
    "    def __le__(self, other):\n",
    "        # this is necessary to sort jobs when they have the same arrival times.\n",
    "        return self.id <= other.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4001411934412399, 0.4105026155801149, 0\n",
      "\n",
      "0.5720238942868375, 0.2383467686762716, 0\n",
      "\n",
      "1.6892393010894828, 0.7553955070531961, 0\n",
      "\n",
      "1.756339572439428, 0.07741279395386719, 0\n",
      "\n",
      "1.7827590288232624, 0.19375523043743875, 0\n",
      "\n",
      "1.7979248278113555, 0.20344628960353223, 0\n",
      "\n",
      "2.321614593718849, 0.10880175821867327, 0\n",
      "\n",
      "2.885513997386044, 0.29790158981221126, 0\n",
      "\n",
      "2.8976510621876375, 0.272793197341875, 0\n",
      "\n",
      "3.04769876009649, 0.17877214435204763, 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def experiment_1():\n",
    "    labda = 2.0\n",
    "    mu = 3.0\n",
    "    rho = labda / mu\n",
    "    F = expon(scale=1.0 / labda)  # interarrival time distribution\n",
    "    G = expon(scale=1.0 / mu)  # service time distribution\n",
    "\n",
    "    num_jobs = 10\n",
    "\n",
    "    time = 0\n",
    "    for i in range(num_jobs):\n",
    "        time += F.rvs()\n",
    "        job = Job()\n",
    "        job.arrival_time = time\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        print(job)\n",
    "\n",
    "\n",
    "experiment_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.busy = False\n",
    "\n",
    "\n",
    "server = Server()\n",
    "queue = []\n",
    "served_jobs = []  # used for statistics\n",
    "\n",
    "\n",
    "def start_service(time, job):\n",
    "    server.busy = True\n",
    "    job.departure_time = time + job.service_time\n",
    "    heappush(stack, (job.departure_time, job, DEPARTURE))\n",
    "\n",
    "\n",
    "def handle_arrival(time, job):\n",
    "    job.queue_length_at_arrival = len(queue)\n",
    "    if server.busy:\n",
    "        queue.append(job)\n",
    "    else:\n",
    "        start_service(time, job)\n",
    "\n",
    "\n",
    "def handle_departure(time, job):\n",
    "    server.busy = False\n",
    "    if queue:  # queue is not empty\n",
    "        next_job = queue.pop(0)  # pop oldest job in queue\n",
    "        start_service(time, next_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical avg. queue length:  1.333333333333333\n",
      "Simulated avg. queue length: 0.1\n",
      "Theoretical avg. sojourn time: 0.9999999999999999\n",
      "Simulated avg. sojourn time: 0.43616282815102236\n"
     ]
    }
   ],
   "source": [
    "def experiment_2():\n",
    "    labda = 2.0\n",
    "    mu = 3.0\n",
    "    rho = labda / mu\n",
    "    F = expon(scale=1.0 / labda)  # interarrival time distribution\n",
    "    G = expon(scale=1.0 / mu)  # service time distribution\n",
    "    num_jobs = 10  # too small, change it to a larger number, and rerun the experiment\n",
    "\n",
    "    time = 0\n",
    "    for i in range(num_jobs):\n",
    "        time += F.rvs()\n",
    "        job = Job()\n",
    "        job.arrival_time = time\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        if typ == ARRIVAL:\n",
    "            handle_arrival(time, job)\n",
    "        else:\n",
    "            handle_departure(time, job)\n",
    "            served_jobs.append(job)\n",
    "\n",
    "    tot_queue = sum(j.queue_length_at_arrival for j in served_jobs)\n",
    "    av_queue_length = tot_queue / len(served_jobs)\n",
    "    print(\"Theoretical avg. queue length: \", rho * rho / (1 - rho))\n",
    "    print(\"Simulated avg. queue length:\", av_queue_length)\n",
    "\n",
    "    tot_sojourn = sum(j.sojourn_time() for j in served_jobs)\n",
    "    av_sojourn_time = tot_sojourn / len(served_jobs)\n",
    "    print(\"Theoretical avg. sojourn time:\", (1. / labda) * rho / (1 - rho))\n",
    "    print(\"Simulated avg. sojourn time:\", av_sojourn_time)\n",
    "\n",
    "\n",
    "experiment_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical avg. queue length:  1.333333333333333\n",
      "Simulated avg. queue length: 0.7495049504950495\n",
      "Theoretical avg. sojourn time: 0.9999999999999999\n",
      "Simulated avg. sojourn time: 0.7389998666992809\n"
     ]
    }
   ],
   "source": [
    "def experiment_2a():\n",
    "    labda = 2.0\n",
    "    mu = 3.0\n",
    "    rho = labda / mu\n",
    "    F = expon(scale=1.0 / labda)  # interarrival time distribution\n",
    "    G = expon(scale=1.0 / mu)  # service time distribution\n",
    "    num_jobs = 1000\n",
    "\n",
    "    time = 0\n",
    "    for i in range(num_jobs):\n",
    "        time += F.rvs()\n",
    "        job = Job()\n",
    "        job.arrival_time = time\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        if typ == ARRIVAL:\n",
    "            handle_arrival(time, job)\n",
    "        else:\n",
    "            handle_departure(time, job)\n",
    "            served_jobs.append(job)\n",
    "\n",
    "    tot_queue = sum(j.queue_length_at_arrival for j in served_jobs)\n",
    "    av_queue_length = tot_queue / len(served_jobs)\n",
    "    print(\"Theoretical avg. queue length: \", rho * rho / (1 - rho))\n",
    "    print(\"Simulated avg. queue length:\", av_queue_length)\n",
    "\n",
    "    tot_sojourn = sum(j.sojourn_time() for j in served_jobs)\n",
    "    av_sojourn_time = tot_sojourn / len(served_jobs)\n",
    "    print(\"Theoretical avg. sojourn time:\", (1. / labda) * rho / (1 - rho))\n",
    "    print(\"Simulated avg. sojourn time:\", av_sojourn_time)\n",
    "\n",
    "\n",
    "experiment_2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.000002695509519, 2.0000027525679416, 5.000005448077461\n",
      "\n",
      "6.000007807537832, 2.000008753692769, 8.000016561230602\n",
      "\n",
      "9.000013148259669, 2.000000735900243, 11.000013884159912\n",
      "\n",
      "12.000022528752462, 2.000001265741311, 14.000023794493773\n",
      "\n",
      "15.000027027621853, 2.0000068305113157, 17.00003385813317\n",
      "\n",
      "18.000033368925727, 2.000003079168399, 20.000036448094125\n",
      "\n",
      "21.000039002721504, 2.0000059730566635, 23.000044975778167\n",
      "\n",
      "24.000039654048052, 2.0000087385505694, 26.00004839259862\n",
      "\n",
      "27.000043611195366, 2.000004346225087, 29.000047957420453\n",
      "\n",
      "30.00004829631633, 2.0000082152836574, 32.000056511599986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "stack = []  # this is the event stack\n",
    "queue = []\n",
    "served_jobs = []  # used for statistics\n",
    "\n",
    "\n",
    "def experiment_3():\n",
    "    labda = 2.0\n",
    "    mu = 3.0\n",
    "    rho = labda / mu\n",
    "    F = uniform(3, 0.00001)\n",
    "    G = uniform(2, 0.00001)\n",
    "    num_jobs = 10\n",
    "\n",
    "    time = 0\n",
    "    for i in range(num_jobs):\n",
    "        time += F.rvs()\n",
    "        job = Job()\n",
    "        job.arrival_time = time\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        if typ == ARRIVAL:\n",
    "            handle_arrival(time, job)\n",
    "        else:\n",
    "            handle_departure(time, job)\n",
    "            served_jobs.append(job)\n",
    "\n",
    "    for j in served_jobs:\n",
    "        print(j)\n",
    "\n",
    "\n",
    "experiment_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK:  0.722222222222222\n"
     ]
    }
   ],
   "source": [
    "def pollaczek_khinchine(labda, G):\n",
    "    ES = G.mean()\n",
    "    rho = labda * ES\n",
    "    ce2 = G.var() / ES / ES\n",
    "    EW = (1. + ce2) / 2 * rho / (1 - rho) * ES\n",
    "    return EW\n",
    "\n",
    "\n",
    "labda = 1. / 3\n",
    "F = expon(scale=1. / labda)  # interarrival time distribution\n",
    "G = uniform(1, 2)\n",
    "\n",
    "print(\"PK: \", labda * pollaczek_khinchine(labda, G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES:  2.5 rho:  0.8333333333333333\n",
      "Theoretical avg. queue length:  2.333333333333332\n",
      "Simulated avg. queue length: 1.63\n",
      "Theoretical avg. sojourn time:  9.499999999999996\n",
      "Avg. sojourn time: 7.575264285500065\n"
     ]
    }
   ],
   "source": [
    "stack = []  # this is the event stack\n",
    "queue = []\n",
    "served_jobs = []  # used for statistics\n",
    "\n",
    "\n",
    "def test_mg1():\n",
    "    job = Job()\n",
    "    labda = 1.0 / 3\n",
    "    F = expon(scale=1.0 / labda)  # interarrival time distribution\n",
    "    G = uniform(1, 3)\n",
    "    print(\"ES: \", G.mean(), \"rho: \", labda * G.mean())\n",
    "\n",
    "    num_jobs = 1000\n",
    "\n",
    "    time = 0\n",
    "    for i in range(num_jobs):\n",
    "        time += F.rvs()\n",
    "        job = Job()\n",
    "        job.arrival_time = time\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        if typ == ARRIVAL:\n",
    "            handle_arrival(time, job)\n",
    "        else:\n",
    "            handle_departure(time, job)\n",
    "            served_jobs.append(job)\n",
    "\n",
    "    tot_queue = sum(j.queue_length_at_arrival for j in served_jobs)\n",
    "    av_queue_length = tot_queue / len(served_jobs)\n",
    "    print(\"Theoretical avg. queue length: \", labda * pollaczek_khinchine(labda, G))\n",
    "    print(\"Simulated avg. queue length:\", av_queue_length)\n",
    "\n",
    "    tot_sojourn = sum(j.sojourn_time() for j in served_jobs)\n",
    "    av_sojourn_time = tot_sojourn / len(served_jobs)\n",
    "    print(\"Theoretical avg. sojourn time: \", pollaczek_khinchine(labda, G) + G.mean())\n",
    "    print(\"Avg. sojourn time:\", av_sojourn_time)\n",
    "\n",
    "\n",
    "test_mg1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "F = np.sort(uniform(0, 120).rvs(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated avg. queue length: 5.0\n",
      "Avg. sojourn time: 17.437362698760733\n",
      "Queue length distribution, sloppy output\n",
      "[(0, 13), (1, 6), (2, 7), (3, 7), (4, 2), (5, 2), (6, 4), (7, 1), (8, 3), (9, 2), (10, 1), (11, 2), (12, 2), (13, 2), (14, 4), (15, 2)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "stack = []  # this is the event stack\n",
    "queue = []\n",
    "served_jobs = []  # used for statistics\n",
    "\n",
    "\n",
    "def check_in():\n",
    "    num_jobs = 60\n",
    "    F = np.sort(uniform(0, 120).rvs(num_jobs))\n",
    "    G = uniform(1, 3)\n",
    "\n",
    "    for i in range(num_jobs):\n",
    "        job = Job()\n",
    "        job.arrival_time = F[i]\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        if typ == ARRIVAL:\n",
    "            handle_arrival(time, job)\n",
    "        else:\n",
    "            handle_departure(time, job)\n",
    "            served_jobs.append(job)\n",
    "\n",
    "    tot_queue = sum(j.queue_length_at_arrival for j in served_jobs)\n",
    "    av_queue_length = tot_queue / len(served_jobs)\n",
    "    print(\"Simulated avg. queue length:\", av_queue_length)\n",
    "\n",
    "    tot_sojourn = sum(j.sojourn_time() for j in served_jobs)\n",
    "    av_sojourn_time = tot_sojourn / len(served_jobs)\n",
    "    print(\"Avg. sojourn time:\", av_sojourn_time)\n",
    "\n",
    "    c = Counter([j.queue_length_at_arrival for j in served_jobs])\n",
    "    print(\"Queue length distribution, sloppy output\")\n",
    "    print(sorted(c.items()))\n",
    "\n",
    "\n",
    "check_in()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [job.arrival_time for job in served_jobs]\n",
    "y = [job.queue_length_at_arrival for job in served_jobs]\n",
    "\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated avg. queue length: 0.85\n",
      "Avg. sojourn time: 4.118316559733122\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack = []  # this is the event stack\n",
    "queue = []\n",
    "served_jobs = []  # used for statistics\n",
    "\n",
    "\n",
    "def check_in_2():\n",
    "    num_jobs = 60\n",
    "    F = np.sort(uniform(0, 150).rvs(num_jobs))\n",
    "    G = uniform(1, 2)\n",
    "\n",
    "    for i in range(num_jobs):\n",
    "        job = Job()\n",
    "        job.arrival_time = F[i]\n",
    "        job.service_time = G.rvs()\n",
    "        heappush(stack, (job.arrival_time, job, ARRIVAL))\n",
    "\n",
    "    while stack:\n",
    "        time, job, typ = heappop(stack)\n",
    "        if typ == ARRIVAL:\n",
    "            handle_arrival(time, job)\n",
    "        else:\n",
    "            handle_departure(time, job)\n",
    "            served_jobs.append(job)\n",
    "\n",
    "    tot_queue = sum(j.queue_length_at_arrival for j in served_jobs)\n",
    "    av_queue_length = tot_queue / len(served_jobs)\n",
    "    print(\"Simulated avg. queue length:\", av_queue_length)\n",
    "\n",
    "    tot_sojourn = sum(j.sojourn_time() for j in served_jobs)\n",
    "    av_sojourn_time = tot_sojourn / len(served_jobs)\n",
    "    print(\"Avg. sojourn time:\", av_sojourn_time)\n",
    "\n",
    "    x = [job.arrival_time for job in served_jobs]\n",
    "    y = [job.queue_length_at_arrival for job in served_jobs]\n",
    "    \n",
    "    plt.plot(x, y, \"o\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "check_in_2()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
